{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CNN Happy vs Sad.ipynb","provenance":[{"file_id":"1tXBPnkRQkz0HrmqnmaBQPt-JNyEQL6KL","timestamp":1609640463073},{"file_id":"https://github.com/lmoroney/dlaicourse/blob/master/Exercises/Exercise%204%20-%20Handling%20Complex%20Images/Exercise%204-Question.ipynb","timestamp":1609333527530}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"UncprnB0ymAE"},"source":["# Happy or Sad classification\n","\n","\n","Below is code with a link to a happy or sad dataset which contains 80 images, 40 happy and 40 sad. \n","Create a convolutional neural network that trains to 100% accuracy on these images,  which cancels training upon hitting training accuracy of >.999\n","\n","Hint -- it will work best with 3 convolutional layers."]},{"cell_type":"code","metadata":{"id":"7Vti6p3PxmpS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609640596283,"user_tz":-330,"elapsed":1000,"user":{"displayName":"Dinesh Vennapoosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgC7DSS-XjfGfKCn6b-tIg5sV7-v-8Yxi1kbDTBMQ=s64","userId":"05727529709798008373"}},"outputId":"1f48e99e-dc04-466d-89bb-0988d83d3661"},"source":["import tensorflow as tf\n","import os\n","import zipfile\n","\n","\n","DESIRED_ACCURACY = 0.999\n","\n","!wget --no-check-certificate \\\n","    \"https://storage.googleapis.com/laurencemoroney-blog.appspot.com/happy-or-sad.zip\" \\\n","    -O \"/tmp/happy-or-sad.zip\"\n","\n","zip_ref = zipfile.ZipFile(\"/tmp/happy-or-sad.zip\", 'r')\n","zip_ref.extractall(\"/tmp/h-or-s\")\n","zip_ref.close()\n","\n","class myCallback(tf.keras.callbacks.Callback):\n","    \n","    def on_epoch_end(self, epoch, logs={}):\n","        \n","        if(logs.get('accuracy')>=0.999):\n","            print(\"\\nReached 99% accuracy so cancelling training!\")\n","            self.model.stop_training = True\n","\n","callback = myCallback()"],"execution_count":5,"outputs":[{"output_type":"stream","text":["--2021-01-03 02:23:16--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/happy-or-sad.zip\n","Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.141.128, 173.194.214.128, 173.194.216.128, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.141.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2670333 (2.5M) [application/zip]\n","Saving to: ‘/tmp/happy-or-sad.zip’\n","\n","\r/tmp/happy-or-sad.z   0%[                    ]       0  --.-KB/s               \r/tmp/happy-or-sad.z 100%[===================>]   2.55M  --.-KB/s    in 0.02s   \n","\n","2021-01-03 02:23:16 (123 MB/s) - ‘/tmp/happy-or-sad.zip’ saved [2670333/2670333]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6DLGbXXI1j_V","executionInfo":{"status":"ok","timestamp":1609640596697,"user_tz":-330,"elapsed":1402,"user":{"displayName":"Dinesh Vennapoosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgC7DSS-XjfGfKCn6b-tIg5sV7-v-8Yxi1kbDTBMQ=s64","userId":"05727529709798008373"}}},"source":["# This Code Block should Define and Compile the Model\n","model = tf.keras.models.Sequential([\n","    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n","    tf.keras.layers.MaxPooling2D(2, 2),\n","    # The second convolution\n","    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","    # The third convolution\n","    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","    # Flatten the results to feed into a DNN\n","    tf.keras.layers.Flatten(),\n","    # 512 neuron hidden layer\n","    tf.keras.layers.Dense(512, activation='relu'),\n","    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('horses') and 1 for the other ('humans')\n","    tf.keras.layers.Dense(1, activation='sigmoid')\n","])\n","\n","from tensorflow.keras.optimizers import RMSprop\n","\n","model.compile(loss='binary_crossentropy',optimizer=RMSprop(lr=0.001),metrics=['accuracy'])"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"4Ap9fUJE1vVu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609640597078,"user_tz":-330,"elapsed":1779,"user":{"displayName":"Dinesh Vennapoosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgC7DSS-XjfGfKCn6b-tIg5sV7-v-8Yxi1kbDTBMQ=s64","userId":"05727529709798008373"}},"outputId":"5312d6f6-2cac-4330-d2d1-862cfd2e0ed4"},"source":["# This code block should create an instance of an ImageDataGenerator called train_datagen \n","# And a train_generator by calling train_datagen.flow_from_directory\n","\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","train_datagen = ImageDataGenerator(rescale=1/255)\n","\n","train_generator = train_datagen.flow_from_directory(\n","        '/tmp/h-or-s/',  # This is the source directory for training images\n","        target_size=(150, 150),  # All images will be resized to 150x150\n","        batch_size=5,\n","        # Since we use binary_crossentropy loss, we need binary labels\n","        class_mode='binary')\n","\n","# Expected output: 'Found 80 images belonging to 2 classes'"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Found 80 images belonging to 2 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"48dLm13U1-Le","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609640625268,"user_tz":-330,"elapsed":29965,"user":{"displayName":"Dinesh Vennapoosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgC7DSS-XjfGfKCn6b-tIg5sV7-v-8Yxi1kbDTBMQ=s64","userId":"05727529709798008373"}},"outputId":"aeee9259-71de-47e9-94f6-ad5dac1f1bbb"},"source":["# This code block should call model.fit and train for\n","# a number of epochs. \n","history = model.fit(\n","      train_generator,\n","      steps_per_epoch=8,  \n","      epochs=15,\n","      verbose=1,\n","      callbacks=[callback])\n","    \n","# Expected output: \"Reached 99.9% accuracy so cancelling training!\"\""],"execution_count":8,"outputs":[{"output_type":"stream","text":["Epoch 1/15\n","8/8 [==============================] - 3s 240ms/step - loss: 5.1086 - accuracy: 0.4857\n","Epoch 2/15\n","8/8 [==============================] - 2s 238ms/step - loss: 0.6429 - accuracy: 0.5696\n","Epoch 3/15\n","8/8 [==============================] - 2s 241ms/step - loss: 0.6059 - accuracy: 0.7102\n","Epoch 4/15\n","8/8 [==============================] - 2s 242ms/step - loss: 0.5566 - accuracy: 0.6613\n","Epoch 5/15\n","8/8 [==============================] - 2s 239ms/step - loss: 0.5572 - accuracy: 0.6021\n","Epoch 6/15\n","8/8 [==============================] - 2s 238ms/step - loss: 0.1701 - accuracy: 0.9714\n","Epoch 7/15\n","8/8 [==============================] - 2s 241ms/step - loss: 0.2859 - accuracy: 0.8901\n","Epoch 8/15\n","8/8 [==============================] - 2s 241ms/step - loss: 0.2940 - accuracy: 0.8566\n","Epoch 9/15\n","8/8 [==============================] - 2s 242ms/step - loss: 0.1247 - accuracy: 0.9607\n","Epoch 10/15\n","8/8 [==============================] - 2s 239ms/step - loss: 0.1322 - accuracy: 0.9253\n","Epoch 11/15\n","8/8 [==============================] - 2s 240ms/step - loss: 0.0981 - accuracy: 0.9577\n","Epoch 12/15\n","8/8 [==============================] - 2s 240ms/step - loss: 0.1434 - accuracy: 0.9144\n","Epoch 13/15\n","8/8 [==============================] - 2s 242ms/step - loss: 0.0378 - accuracy: 0.9831\n","Epoch 14/15\n","8/8 [==============================] - 2s 243ms/step - loss: 0.0182 - accuracy: 1.0000\n","\n","Reached 99% accuracy so cancelling training!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3sMtYIP6EAPe"},"source":[" Use your favourite emojis to predict Happy or Sad."]}]}